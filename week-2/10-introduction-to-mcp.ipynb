{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa71fc4b",
   "metadata": {},
   "source": [
    "# Introduction to MCP (Model-Context Protocol)\n",
    "\n",
    "https://github.com/alexeygrigorev/workshops/tree/main/agents-mcp\n",
    "\n",
    "MCP (Model Context Protocol) is an open protocol developed by Anthropic that standardizes how AI models (or “agents”) connect and communicate with external tools, databases, and APIs.\n",
    "\n",
    "They describe it as \"USB Type-C for AI tools\": it provides a universal interface that allows any AI agent to access a tool without needing custom integration code.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "- MCP Server is a bridge between the agent and the tool.\n",
    "- The agent communicates with the MCP server using a defined protocol.\n",
    "- The MCP server handles logic for the tool (e.g., querying a database, searching documents, adding entries).\n",
    "- The tool responds to the MCP server, which then passes the result back to the agent.\n",
    "\n",
    "So developers only need to implement a tool once as an MCP server, and it becomes reusable by any agent that supports MCP.\n",
    "\n",
    "## PostgreSQL example\n",
    "\n",
    "Imagine you have a PostgreSQL database containing customer data, and you want your AI agent to query it.\n",
    "\n",
    "Normally, every developer would have to write custom code for their agent to connect to PostgreSQL (handling authentication, queries, schemas, etc.).\n",
    "\n",
    "With MCP, you can instead create a Postgres MCP Server:\n",
    "\n",
    "1. The MCP server knows how to:\n",
    "  - Connect to your PostgreSQL instance.\n",
    "  - Retrieve database schemas.\n",
    "  - Execute SQL queries, such as selecting customers from a specific city.\n",
    "\n",
    "2. The AI agent doesn’t need to know SQL or PostgreSQL details — it just sends a standard MCP request like “Find all customers in London”.\n",
    "\n",
    "3. The MCP server translates this into a SQL query, runs it on the PostgreSQL database, and returns a structured response with the matching records.\n",
    "\n",
    "Now, any agent (running in Jupyter, VS Code, or another environment) can use this Postgres MCP server without writing any SQL or integration code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84794902",
   "metadata": {},
   "source": [
    "## Creating MCP Server\n",
    "\n",
    "Install:\n",
    "```bash\n",
    "pip install uv # if you don't have uv\n",
    "uv init\n",
    "uv add minsearch requests fastmcp\n",
    "```\n",
    "\n",
    "Create a file `search_tools.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6f4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "class SearchTools:\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search the FAQ database for entries matching the given query.\n",
    "    \n",
    "        Args:\n",
    "            query (str): Search query text to look up in the course FAQ.\n",
    "    \n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\n",
    "        \"\"\"\n",
    "        boost = {'question': 3.0, 'section': 0.5}\n",
    "    \n",
    "        results = self.index.search(\n",
    "            query=query,\n",
    "            filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "            boost_dict=boost,\n",
    "            num_results=5,\n",
    "        )\n",
    "    \n",
    "        return results\n",
    "\n",
    "    def add_entry(self, question: str, answer: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a new entry to the FAQ database.\n",
    "    \n",
    "        Args:\n",
    "            question (str): The question to be added to the FAQ database.\n",
    "            answer (str): The corresponding answer to the question.\n",
    "        \"\"\"\n",
    "        doc = {\n",
    "            'question': question,\n",
    "            'text': answer,\n",
    "            'section': 'user added',\n",
    "            'course': 'data-engineering-zoomcamp'\n",
    "        }\n",
    "        self.index.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6110a",
   "metadata": {},
   "source": [
    "Create a `main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7923c1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.', 'section': 'Module 6: streaming with kafka', 'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.', 'section': 'Module 6: streaming with kafka', 'question': 'Kafka- python videos have low audio and hard to follow up', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}, {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build', 'course': 'data-engineering-zoomcamp'}]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "from search_tools import SearchTools\n",
    "\n",
    "def init_index():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            documents.append(doc)\n",
    "\n",
    "\n",
    "    index = AppendableIndex(\n",
    "        text_fields=[\"question\", \"text\", \"section\"],\n",
    "        keyword_fields=[\"course\"]\n",
    "    )\n",
    "\n",
    "    index.fit(documents)\n",
    "    return index\n",
    "\n",
    "\n",
    "def init_tools():\n",
    "    index = init_index()\n",
    "    return SearchTools(index)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tools = init_tools()\n",
    "    print(tools.search(\"How do I install Kafka?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047eee0",
   "metadata": {},
   "source": [
    "Let's expose these tools with MCP. For that, we will need to create an MCP server. There are many frameworks for creating them. We will use [FastMCP](https://github.com/jlowin/fastmcp).\n",
    "\n",
    "This is the simplest possible MCP server (taken from the docs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo 🚀\")\n",
    "\n",
    "@mcp.tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b9ce4",
   "metadata": {},
   "source": [
    "Add this to `main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8239a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "from toyaikit.tools import wrap_instance_methods\n",
    "\n",
    "\n",
    "def init_mcp():\n",
    "    mcp = FastMCP(\"Demo 🚀\")\n",
    "    agent_tools = init_tools()\n",
    "    wrap_instance_methods(mcp.tool, agent_tools)\n",
    "    return mcp\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp = init_mcp()\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9b203",
   "metadata": {},
   "source": [
    "Run it:\n",
    "\n",
    "```bash\n",
    "uv run python main.py\n",
    "```\n",
    "\n",
    "It uses standard input/output as transport:\n",
    "\n",
    "```\n",
    " 📦 Transport:       STDIO  \n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc2f36",
   "metadata": {},
   "source": [
    "Which means, we can paste things into our terminal to test it (and simulate the interaction with the server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c42e7",
   "metadata": {},
   "source": [
    "# MCP STDIO Transport: Communicating with Local MCP Servers\n",
    "\n",
    "## Handshake Sequence\n",
    "\n",
    "First, we need to initialize the connection. We do it with the handshake sequence:\n",
    "\n",
    "1. Send the ininialization request\n",
    "2. Confirm the initialization\n",
    "3. Now can see the list of available tools\n",
    "\n",
    "Let's do this. Send the initialization request:\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}\n",
    "```\n",
    "\n",
    "We get back something like:\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Demo 🚀\",\"version\":\"1.13.1\"}}}\n",
    "```\n",
    "\n",
    "This is a confirmation that we can proceed.\n",
    "\n",
    "Next, confirm the initialization:\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}\n",
    "```\n",
    "\n",
    "We don't get back anything\n",
    "\n",
    "## Using Tools\n",
    "\n",
    "Now we can see the list of available tools:\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\"}\n",
    "```\n",
    "\n",
    "We get back the list\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"tools\":[{\"name\":\"add_entry\",\"description\":\"Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.\",\"inputSchema\":{\"properties\":{\"question\":{\"type\":\"string\"},\"answer\":{\"type\":\"string\"}},\"required\":[\"question\",\"answer\"],\"type\":\"object\"},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}},{\"name\":\"search\",\"description\":\"Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\",\"inputSchema\":{\"properties\":{\"query\":{\"type\":\"string\"}},\"required\":[\"query\"],\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"items\":{\"additionalProperties\":true,\"type\":\"object\"},\"type\":\"array\"}},\"required\":[\"result\"],\"type\":\"object\",\"x-fastmcp-wrap-result\":true},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}}]}}\n",
    "```\n",
    "\n",
    "Formatted:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 2,\n",
    "  \"result\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"name\": \"add_entry\",\n",
    "        \"description\": \"Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.\",\n",
    "        \"inputSchema\": {\n",
    "          \"properties\": {\n",
    "            \"question\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"answer\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"question\",\n",
    "            \"answer\"\n",
    "          ],\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"_meta\": {\n",
    "          \"_fastmcp\": {\n",
    "            \"tags\": [\n",
    "              \n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"search\",\n",
    "        \"description\": \"Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.\",\n",
    "        \"inputSchema\": {\n",
    "          \"properties\": {\n",
    "            \"query\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"query\"\n",
    "          ],\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"outputSchema\": {\n",
    "          \"properties\": {\n",
    "            \"result\": {\n",
    "              \"items\": {\n",
    "                \"additionalProperties\": true,\n",
    "                \"type\": \"object\"\n",
    "              },\n",
    "              \"type\": \"array\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"result\"\n",
    "          ],\n",
    "          \"type\": \"object\",\n",
    "          \"x-fastmcp-wrap-result\": true\n",
    "        },\n",
    "        \"_meta\": {\n",
    "          \"_fastmcp\": {\n",
    "            \"tags\": [\n",
    "              \n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "> Note: the schema for tools is somewhat similar to the OpenAI's function calling, but not the same.\n",
    "\n",
    "Invoke a function:\n",
    "\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"search\", \"arguments\": {\"query\": \"how do I run kafka?\"}}}\n",
    "```\n",
    "\n",
    "And we get a response like:\n",
    "\n",
    "```json\n",
    "{\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"...\"}],\"isError\":false}}\n",
    "```\n",
    "\n",
    "\n",
    "## Simple MCP Client (For Testing Only)\n",
    "\n",
    "If you need an MCP client, you should use the built-in one from FastMCP. However, it's async (which is good for production cases), so testing it inside Jupyter is difficult.\n",
    "\n",
    "Let's invoke it from Jupyter with ToyAIKit:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ae12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPClient, SubprocessMCPTransport\n",
    "\n",
    "command = \"uv run python main.py\".split()\n",
    "workdir = \"mcp\"\n",
    "\n",
    "client = MCPClient(\n",
    "    transport=SubprocessMCPTransport(\n",
    "        server_command=command,\n",
    "        workdir=workdir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bdbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: uv run python main.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.16.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n",
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'add_entry',\n",
       "  'description': 'Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.',\n",
       "  'inputSchema': {'properties': {'question': {'type': 'string'},\n",
       "    'answer': {'type': 'string'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'type': 'object'},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}},\n",
       " {'name': 'search',\n",
       "  'description': 'Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.',\n",
       "  'inputSchema': {'properties': {'query': {'type': 'string'}},\n",
       "   'required': ['query'],\n",
       "   'type': 'object'},\n",
       "  'outputSchema': {'properties': {'result': {'items': {'additionalProperties': True,\n",
       "      'type': 'object'},\n",
       "     'type': 'array'}},\n",
       "   'required': ['result'],\n",
       "   'type': 'object',\n",
       "   'x-fastmcp-wrap-result': True},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can:\n",
    "\n",
    "# Start the server (run the command)\n",
    "client.start_server()\n",
    "\n",
    "# Send \"initialize\"\n",
    "client.initialize()\n",
    "\n",
    "# Send \"initialized\"\n",
    "client.initialized()\n",
    "\n",
    "# get tools\n",
    "client.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b659957",
   "metadata": {},
   "source": [
    "We can do all 4 with one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a8bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: uv run python main.py\n",
      "Waiting 0.5 seconds for server to stabilize...\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.16.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n",
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    }
   ],
   "source": [
    "client.full_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057180ae",
   "metadata": {},
   "source": [
    "Lets invoke the search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2ae69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'how do I run docker?'}\n"
     ]
    }
   ],
   "source": [
    "result = client.call_tool('search', {'query': 'how do I run docker?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25258bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': [{'type': 'text', 'text': '[{\"text\":\"When you run this command second time\\\\ndocker run -it \\\\\\\\\\\\n-e POSTGRES_USER=\\\\\"root\\\\\" \\\\\\\\\\\\n-e POSTGRES_PASSWORD=\\\\\"root\\\\\" \\\\\\\\\\\\n-e POSTGRES_DB=\\\\\"ny_taxi\\\\\" \\\\\\\\\\\\n-v <your path>:/var/lib/postgresql/data \\\\\\\\\\\\n-p 5432:5432 \\\\\\\\\\\\npostgres:13\\\\nThe error message above could happen. That means you should not mount on the second run. This command helped me:\\\\nWhen you run this command second time\\\\ndocker run -it \\\\\\\\\\\\n-e POSTGRES_USER=\\\\\"root\\\\\" \\\\\\\\\\\\n-e POSTGRES_PASSWORD=\\\\\"root\\\\\" \\\\\\\\\\\\n-e POSTGRES_DB=\\\\\"ny_taxi\\\\\" \\\\\\\\\\\\n-p 5432:5432 \\\\\\\\\\\\npostgres:13\",\"section\":\"Module 1: Docker and Terraform\",\"question\":\"Docker - Error response from daemon: error while creating buildmount source path \\'/run/desktop/mnt/host/c/<your path>\\': mkdir /run/desktop/mnt/host/c: file exists\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"You may have this error:\\\\n$ docker run -it ubuntu bash\\\\nthe input device is not a TTY. If you are using mintty, try prefixing the command with \\'winpty\\'\\\\nerror:\\\\nSolution:\\\\nUse winpty before docker command (source)\\\\n$ winpty docker run -it ubuntu bash\\\\nYou also can make an alias:\\\\necho \\\\\"alias docker=\\'winpty docker\\'\\\\\" >> ~/.bashrc\\\\nOR\\\\necho \\\\\"alias docker=\\'winpty docker\\'\\\\\" >> ~/.bash_profile\",\"section\":\"Module 1: Docker and Terraform\",\"question\":\"Docker - The input device is not a TTY (Docker run for Windows)\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"As the official Docker for Windows documentation says, the Docker engine can either use the\\\\nHyper-V or WSL2 as its backend. However, a few constraints might apply\\\\nWindows 10 Pro / 11 Pro Users: \\\\nIn order to use Hyper-V as its back-end, you MUST have it enabled first, which you can do by following the tutorial: Enable Hyper-V Option on Windows 10 / 11\\\\nWindows 10 Home / 11 Home Users: \\\\nOn the other hand, Users of the \\'Home\\' version do NOT have the option Hyper-V option enabled, which means, you can only get Docker up and running using the WSL2 credentials(Windows Subsystem for Linux). Url\\\\nYou can find the detailed instructions to do so here: rt ghttps://pureinfotech.com/install-wsl-windows-11/\\\\nIn case, you run into another issue while trying to install WSL2 (WslRegisterDistribution failed with error: 0x800701bc), Make sure you update the WSL2 Linux Kernel, following the guidelines here: \\\\n\\\\nhttps://github.com/microsoft/WSL/issues/5393\",\"section\":\"Module 1: Docker and Terraform\",\"question\":\"Docker - Error during connect: In the default daemon configuration on Windows, the docker client must be run with elevated privileges to connect.: Post: \\\\\"http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/create\\\\\" : open //./pipe/docker_engine: The system cannot find the file specified\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"It is recommended by the Docker do\\\\n[Windows 10 / 11 Home Edition] If you\\'re running a Home Edition, you can still make it work with WSL2 (Windows Subsystem for Linux) by following the tutorial here\\\\nIf even after making sure your WSL2 (or Hyper-V) is set up accordingly, Docker remains stuck, you can try the option to Reset to Factory Defaults or do a fresh install.\",\"section\":\"Module 1: Docker and Terraform\",\"question\":\"Should I run docker commands from the windows file system or a file system of a Linux distribution in WSL?\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"This happens if you did not create the docker group and added your user. Follow these steps from the link:\\\\nguides/docker-without-sudo.md at main · sindresorhus/guides · GitHub\\\\nAnd then press ctrl+D to log-out and log-in again. pgAdmin: Maintain state so that it remembers your previous connection\\\\nIf you are tired of having to setup your database connection each time that you fire up the containers, all you have to do is create a volume for pgAdmin:\\\\nIn your docker-compose.yaml file, enter the following into your pgAdmin declaration:\\\\nvolumes:\\\\n- type: volume\\\\nsource: pgadmin_data\\\\ntarget: /var/lib/pgadmin\\\\nAlso add the following to the end of the file:ls\\\\nvolumes:\\\\nPgadmin_data:\",\"section\":\"Module 1: Docker and Terraform\",\"question\":\"Docker-Compose - dial unix /var/run/docker.sock: connect: permission denied\",\"course\":\"data-engineering-zoomcamp\"}]'}], 'structuredContent': {'result': [{'text': 'When you run this command second time\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-v <your path>:/var/lib/postgresql/data \\\\\\n-p 5432:5432 \\\\\\npostgres:13\\nThe error message above could happen. That means you should not mount on the second run. This command helped me:\\nWhen you run this command second time\\ndocker run -it \\\\\\n-e POSTGRES_USER=\"root\" \\\\\\n-e POSTGRES_PASSWORD=\"root\" \\\\\\n-e POSTGRES_DB=\"ny_taxi\" \\\\\\n-p 5432:5432 \\\\\\npostgres:13', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - Error response from daemon: error while creating buildmount source path '/run/desktop/mnt/host/c/<your path>': mkdir /run/desktop/mnt/host/c: file exists\", 'course': 'data-engineering-zoomcamp'}, {'text': 'You may have this error:\\n$ docker run -it ubuntu bash\\nthe input device is not a TTY. If you are using mintty, try prefixing the command with \\'winpty\\'\\nerror:\\nSolution:\\nUse winpty before docker command (source)\\n$ winpty docker run -it ubuntu bash\\nYou also can make an alias:\\necho \"alias docker=\\'winpty docker\\'\" >> ~/.bashrc\\nOR\\necho \"alias docker=\\'winpty docker\\'\" >> ~/.bash_profile', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - The input device is not a TTY (Docker run for Windows)', 'course': 'data-engineering-zoomcamp'}, {'text': \"As the official Docker for Windows documentation says, the Docker engine can either use the\\nHyper-V or WSL2 as its backend. However, a few constraints might apply\\nWindows 10 Pro / 11 Pro Users: \\nIn order to use Hyper-V as its back-end, you MUST have it enabled first, which you can do by following the tutorial: Enable Hyper-V Option on Windows 10 / 11\\nWindows 10 Home / 11 Home Users: \\nOn the other hand, Users of the 'Home' version do NOT have the option Hyper-V option enabled, which means, you can only get Docker up and running using the WSL2 credentials(Windows Subsystem for Linux). Url\\nYou can find the detailed instructions to do so here: rt ghttps://pureinfotech.com/install-wsl-windows-11/\\nIn case, you run into another issue while trying to install WSL2 (WslRegisterDistribution failed with error: 0x800701bc), Make sure you update the WSL2 Linux Kernel, following the guidelines here: \\n\\nhttps://github.com/microsoft/WSL/issues/5393\", 'section': 'Module 1: Docker and Terraform', 'question': 'Docker - Error during connect: In the default daemon configuration on Windows, the docker client must be run with elevated privileges to connect.: Post: \"http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/create\" : open //./pipe/docker_engine: The system cannot find the file specified', 'course': 'data-engineering-zoomcamp'}, {'text': \"It is recommended by the Docker do\\n[Windows 10 / 11 Home Edition] If you're running a Home Edition, you can still make it work with WSL2 (Windows Subsystem for Linux) by following the tutorial here\\nIf even after making sure your WSL2 (or Hyper-V) is set up accordingly, Docker remains stuck, you can try the option to Reset to Factory Defaults or do a fresh install.\", 'section': 'Module 1: Docker and Terraform', 'question': 'Should I run docker commands from the windows file system or a file system of a Linux distribution in WSL?', 'course': 'data-engineering-zoomcamp'}, {'text': 'This happens if you did not create the docker group and added your user. Follow these steps from the link:\\nguides/docker-without-sudo.md at main · sindresorhus/guides · GitHub\\nAnd then press ctrl+D to log-out and log-in again. pgAdmin: Maintain state so that it remembers your previous connection\\nIf you are tired of having to setup your database connection each time that you fire up the containers, all you have to do is create a volume for pgAdmin:\\nIn your docker-compose.yaml file, enter the following into your pgAdmin declaration:\\nvolumes:\\n- type: volume\\nsource: pgadmin_data\\ntarget: /var/lib/pgadmin\\nAlso add the following to the end of the file:ls\\nvolumes:\\nPgadmin_data:', 'section': 'Module 1: Docker and Terraform', 'question': 'Docker-Compose - dial unix /var/run/docker.sock: connect: permission denied', 'course': 'data-engineering-zoomcamp'}]}, 'isError': False}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581276b7",
   "metadata": {},
   "source": [
    "If we want to use MCP with plan OpenAI API, we need to convert the MCP tools into the calling schemas. We can do it with ToyAIKit, you can see the code [here](https://github.com/alexeygrigorev/toyaikit/blob/main/toyaikit/mcp/mcp_tools.py#L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09808822-1b29-443b-a4cc-9c03b0581a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPClient, SubprocessMCPTransport\n",
    "\n",
    "command = \"uv run python main.py\".split()\n",
    "workdir = \"mcp\"\n",
    "\n",
    "client = MCPClient(\n",
    "    transport=SubprocessMCPTransport(\n",
    "        server_command=command,\n",
    "        workdir=workdir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef3f0fe-597e-4c0f-a244-996046cede14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: uv run python main.py\n",
      "Waiting 0.5 seconds for server to stabilize...\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo 🚀', 'version': '1.16.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n",
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    }
   ],
   "source": [
    "client.full_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e051b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You are an assistant answer question from the user.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894c6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.mcp import MCPTools\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner\n",
    "\n",
    "mcp_tools = MCPTools(client)\n",
    "\n",
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient(model='gpt-4o-mini')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11bbb8",
   "metadata": {},
   "source": [
    "Run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: How do I install kafka?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Installing Apache Kafka involves several steps. Here's a basic guide for setting it up on a local machine:</p>\n",
       "<h3>Prerequisites</h3>\n",
       "<ol>\n",
       "<li><p><strong>Java Development Kit (JDK)</strong>: Kafka requires Java. Make sure you have JDK 8 or higher installed. You can check your Java version with:</p>\n",
       "<pre><code class=\"language-bash\">java -version\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Apache Zookeeper</strong>: Kafka uses Zookeeper for managing distributed brokers. It is bundled with Kafka, so you don't need to install it separately.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<h3>Installation Steps</h3>\n",
       "<ol>\n",
       "<li><p><strong>Download Kafka</strong>: Get the latest Kafka release from the <a href=\"https://kafka.apache.org/downloads\">Apache Kafka Downloads page</a>. For example, you can use:</p>\n",
       "<pre><code class=\"language-bash\">wget http://apache.mirrors.spacedump.net/kafka/2.8.0/kafka_2.12-2.8.0.tgz\n",
       "</code></pre>\n",
       "<p>(Note: Replace the URL with the latest version URL)</p>\n",
       "</li>\n",
       "<li><p><strong>Extract Kafka</strong>:</p>\n",
       "<pre><code class=\"language-bash\">tar -xzf kafka_2.12-2.8.0.tgz\n",
       "cd kafka_2.12-2.8.0\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Start Zookeeper</strong>: Before starting Kafka, you need to start Zookeeper. You can do this with:</p>\n",
       "<pre><code class=\"language-bash\">bin/zookeeper-server-start.sh config/zookeeper.properties\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Start Kafka Server</strong>: Open a new terminal window and run:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-server-start.sh config/server.properties\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Create a Topic</strong> (optional): To create a topic named &quot;test&quot;:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Send Messages</strong>: You can send messages to your topic by running the producer:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --topic test --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "</li>\n",
       "<li><p><strong>Read Messages</strong>: In another terminal, you can read messages from the topic:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "</li>\n",
       "</ol>\n",
       "<h3>Stopping Kafka and Zookeeper</h3>\n",
       "<p>To stop Kafka, you can use:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-server-stop.sh\n",
       "</code></pre>\n",
       "<p>And for Zookeeper:</p>\n",
       "<pre><code class=\"language-bash\">bin/zookeeper-server-stop.sh\n",
       "</code></pre>\n",
       "<h3>Additional Notes</h3>\n",
       "<ul>\n",
       "<li>Make sure the configurations in <code>server.properties</code> match your requirements.</li>\n",
       "<li>Kafka can be run on various environments (Docker, Kubernetes) for production settings.</li>\n",
       "</ul>\n",
       "<p>This setup is basic and meant for development. For production, you’ll want to consider additional configurations and setups.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9604e",
   "metadata": {},
   "source": [
    "If we want to use the client from FastMCP, it looks like that (but we won't do it here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with Client(\"uv run python main.py\") as mcp_client:\n",
    "        # ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
