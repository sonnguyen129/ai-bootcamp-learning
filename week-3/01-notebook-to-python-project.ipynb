{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976c5def",
   "metadata": {},
   "source": [
    "# Converting Jupyter Notebook to Python Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2be94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70029e9",
   "metadata": {},
   "source": [
    "Start a new project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa140be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv init\n",
    "!uv add openai requests pydantic-ai minsearch python-frontmatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203616f",
   "metadata": {},
   "source": [
    "Get the docs.py file from week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70037628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-21 11:55:43--  https://github.com/alexeygrigorev/ai-bootcamp-codespace/raw/refs/heads/main/week1/docs.py\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/ai-bootcamp-codespace/refs/heads/main/week1/docs.py [following]\n",
      "--2025-10-21 11:55:44--  https://raw.githubusercontent.com/alexeygrigorev/ai-bootcamp-codespace/refs/heads/main/week1/docs.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8000::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8583 (8.4K) [text/plain]\n",
      "Saving to: ‘docs.py’\n",
      "\n",
      "docs.py             100%[===================>]   8.38K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-10-21 11:55:44 (652 KB/s) - ‘docs.py’ saved [8583/8583]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/ai-bootcamp-codespace/raw/refs/heads/main/week1/docs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d5af9",
   "metadata": {},
   "source": [
    "## Search Tools Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db1b9a",
   "metadata": {},
   "source": [
    "Now create search tools. This is out search_tools.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ec3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import Index\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import docs\n",
    "\n",
    "\n",
    "class SearchTools:\n",
    "\n",
    "    def __init__(self, index: Index):\n",
    "        self.index = index\n",
    "\n",
    "    def search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search the index for documents matching the given query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query string.\n",
    "\n",
    "        Returns:\n",
    "            A list of search results\n",
    "        \"\"\"\n",
    "        return self.index.search(\n",
    "            query=query,\n",
    "            num_results=5,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ac37d",
   "metadata": {},
   "source": [
    "Put the index preparation code in a separate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_index():\n",
    "    github_data = docs.read_github_data()\n",
    "    parsed_data = docs.parse_data(github_data)\n",
    "    chunks = docs.chunk_documents(parsed_data)\n",
    "\n",
    "    index = Index(\n",
    "        text_fields=[\"title\", \"description\", \"content\"]\n",
    "    )\n",
    "\n",
    "    index.fit(chunks)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35008c",
   "metadata": {},
   "source": [
    "Add caching to avoid reprocessing data every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725eff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def prepare_index_cached():\n",
    "    cache_dir = Path(\".cache\")\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    index_path = cache_dir / \"search_index.bin\"\n",
    "\n",
    "    if index_path.exists():\n",
    "        with open(index_path, \"rb\") as f:\n",
    "            index = pickle.load(f)\n",
    "            return index\n",
    "\n",
    "    index = prepare_index()\n",
    "\n",
    "    with open(index_path, \"wb\") as f:\n",
    "        pickle.dump(index, f)\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c54677",
   "metadata": {},
   "source": [
    "Put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_search_tools():\n",
    "    index = prepare_index_cached()\n",
    "    return SearchTools(index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8ebdb",
   "metadata": {},
   "source": [
    "Here's a summary of what each class/function is doing:\n",
    "\n",
    "- **SearchTools class**: A wrapper around index.\n",
    "\n",
    "- **prepare_index()**: Downloads GitHub documentation data, parses it, chunks it into smaller pieces, and creates the index.\n",
    "\n",
    "- **prepare_index_cached()**: A wrapper around prepare_index() that saves the index to disk. If a cached version exists, it loads that instead of reprocessing everything.\n",
    "\n",
    "- **prepare_search_tools()**: The main entry point that returns a ready-to-use SearchTools instance.\n",
    "\n",
    "We added **prepare_index_cached** - so we don't need to redo the indexing every time.\n",
    "\n",
    "Add .cache to .gitignore (along with other files) so we don't accidentally commit them to git:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53884e",
   "metadata": {},
   "source": [
    "```\n",
    ".cache\n",
    ".pytest_cache\n",
    "__pycache__\n",
    ".venv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8f8c3",
   "metadata": {},
   "source": [
    "## Search Agent Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad70c9c",
   "metadata": {},
   "source": [
    "Now implement the search agent (search_agent.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49212ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.messages import FunctionToolCallEvent\n",
    "import search_tools\n",
    "\n",
    "\n",
    "class NamedCallback:\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self.agent_name = agent.name\n",
    "\n",
    "    async def print_function_calls(self, ctx, event):\n",
    "        # Detect nested streams\n",
    "        if hasattr(event, \"__aiter__\"):\n",
    "            async for sub in event:\n",
    "                await self.print_function_calls(ctx, sub)\n",
    "            return\n",
    "\n",
    "        if isinstance(event, FunctionToolCallEvent):\n",
    "            tool_name = event.part.tool_name\n",
    "            args = event.part.args\n",
    "            print(f\"TOOL CALL ({self.agent_name}): {tool_name}({args})\")\n",
    "\n",
    "    async def __call__(self, ctx, event):\n",
    "        return await self.print_function_calls(ctx, event)\n",
    "\n",
    "\n",
    "search_instructions = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_agent():\n",
    "    tools = search_tools.prepare_search_tools()\n",
    "\n",
    "    return Agent(\n",
    "        name=\"search\",\n",
    "        instructions=search_instructions,\n",
    "        tools=[tools.search],\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601451c",
   "metadata": {},
   "source": [
    "Here's what each part does:\n",
    "\n",
    "- **NamedCallback class**: This helps us monitor what function calls the agent makes. We implemented it when creating the deep research agent, so I just took it form there.\n",
    "\n",
    "- **create_agent()**: sets up the complete agent with search tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef8576",
   "metadata": {},
   "source": [
    "## Main Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e81415",
   "metadata": {},
   "source": [
    "And put everything together in main.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import search_agent\n",
    "import asyncio\n",
    "\n",
    "agent = search_agent.create_agent()\n",
    "agent_callback = search_agent.NamedCallback(agent)\n",
    "\n",
    "\n",
    "async def run_agent(user_prompt: str):\n",
    "\n",
    "    results = await agent.run(\n",
    "        user_prompt=user_prompt,\n",
    "        event_stream_handler=agent_callback\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "result = asyncio.run(run_agent(\"What is LLM evaluation?\"))\n",
    "\n",
    "print(result.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a69b3d",
   "metadata": {},
   "source": [
    "This main file brings everything together.\n",
    "\n",
    "It creates the agent, sets up monitoring with the callback, and provides a simple function to run queries.\n",
    "\n",
    "The example query asks about LLM evaluation, which should trigger the agent to search the documentation and provide a comprehensive answer based on what it finds.\n",
    "\n",
    "Now let's add tests!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
